# OpenAI Configuration
OPENAI_API_KEY=your-openai-api-key
OPENAI_BASE_URL=https://api.openai.com/v1
DEFAULT_MODEL=us.anthropic.claude-3-7-sonnet-20250219-v1:0

# AWS Configuration  
AWS_REGION=us-east-1
OPENSEARCH_ENDPOINT=https://your-opensearch-domain.region.es.amazonaws.com

# Optional: Langfuse for observability
LANGFUSE_HOST=https://cloud.langfuse.com
LANGFUSE_PUBLIC_KEY=your-public-key
LANGFUSE_SECRET_KEY=your-secret-key

# Application Settings
KNOWLEDGE_DIR=knowledge
OUTPUT_DIR=output
EMBEDDING_MODEL=text-embedding-3-small
VECTOR_INDEX_NAME=knowledge-embeddings
TOP_K_RESULTS=5

# Configuration Notes:
# 
# OPENAI_API_KEY: Your OpenAI API key or compatible embedding service key
# OPENAI_BASE_URL: Endpoint for embedding generation (OpenAI or compatible service)
# DEFAULT_MODEL: Strands SDK model ID (defaults to Claude 3.7 Sonnet on Bedrock)
# 
# AWS_REGION: AWS region for OpenSearch and other AWS services
# OPENSEARCH_ENDPOINT: Your AWS OpenSearch domain endpoint
# 
# LANGFUSE_*: Optional observability tracking (leave empty to disable)
# 
# KNOWLEDGE_DIR: Directory containing knowledge files to embed
# OUTPUT_DIR: Directory for generated outputs and reports
# EMBEDDING_MODEL: Model name for generating embeddings
# VECTOR_INDEX_NAME: OpenSearch index name for vector storage
# TOP_K_RESULTS: Default number of search results to return
